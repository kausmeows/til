## Why do we use an activation function ?

If we do not have the activation function the `weights` and `bias` would simply do a `linear transformation`. A linear equation is simple to solve but is limited in its capacity to solve complex problems and have less power to learn complex functional mappings from data. A neural network without an activation function is just a linear regression model.

Generally, `neural networks` use `non-linear activation functions`, which can help the network learn complex data, compute and learn almost any function representing a question, and provide accurate predictions.